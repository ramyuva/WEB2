{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element_by_xpath(\"//*[@id='container']/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "search_btn.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn1=driver.find_element_by_xpath(\"//*[@id='container']/div/div[1]/div[1]/div[2]/div[2]/form/div/button/svg/g/path[2]\")\n",
    "search_btn1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Brand  \\\n",
      "0                      AMROX    \n",
      "1                      Birde    \n",
      "2                     Chevit    \n",
      "3               Robbie jones    \n",
      "4        World Wear Footwear    \n",
      "..                        ...   \n",
      "115                    Axter    \n",
      "116             Robbie jones    \n",
      "117                   Chevit    \n",
      "118                Rockfield    \n",
      "119  Bond Street By Red Tape    \n",
      "\n",
      "                                          product_desc   price Discount  \n",
      "0    Product DetailsColorBlackOuter MaterialMeshIde...    ₹399  73% off  \n",
      "1    Product DetailsColorGreyOuter MaterialMeshIdea...    ₹359  64% off  \n",
      "2    Product DetailsColorMulticolorInner MaterialFa...    ₹474  76% off  \n",
      "3    Product DetailsColorWhiteInner MaterialCanvasO...    ₹399  60% off  \n",
      "4    Product DetailsColorMulticolorOuter MaterialCa...    ₹499  75% off  \n",
      "..                                                 ...     ...      ...  \n",
      "115  Product DetailsColorMulticolorOuter MaterialCa...    ₹299  70% off  \n",
      "116  Product DetailsColorWhiteInner MaterialCanvasO...    ₹499  50% off  \n",
      "117  Product DetailsColorRed, BlackInner MaterialCa...    ₹236  52% off  \n",
      "118  Product DetailsColorBlackOuter MaterialSynthet...    ₹499  50% off  \n",
      "119  Product DetailsColorWhiteOuter MaterialSynthet...  ₹1,049  70% off  \n",
      "\n",
      "[120 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function Definition\n",
    "def flipkart_shoe(url):\n",
    "    driver=webdriver.Chrome('chromedriver.exe')\n",
    "    start_page=0\n",
    "    end_page=2\n",
    "    urls = []\n",
    "    brand=[]\n",
    "    product_desc=[]\n",
    "    price=[]\n",
    "    discount=[]\n",
    "    #loop to fetch urls of each mobile till page 3\n",
    "    for page in range(start_page,end_page+1):\n",
    "        driver.get(url)\n",
    "        soup= BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        prod_urls = soup.find_all('a', attrs ={'class':'IRpwTa'})\n",
    "        for prod in prod_urls:\n",
    "            urls.append('https://www.flipkart.com'+prod.get('href'))\n",
    "    \n",
    "    #loop to scrap required details from each mobile page\n",
    "    for url in urls:\n",
    "        driver.get(url)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        n = soup.find('h1',attrs={'class':'yhB1nd'})\n",
    "        if n is not None:\n",
    "            brand.append(n.find('span').text.replace('\\n',''))\n",
    "        else:\n",
    "            brand.append('-')\n",
    "        desc = soup.find('div', attrs = {'class':'_2yIA0Y'})\n",
    "        if desc is not None:\n",
    "            product_desc.append(desc.text)\n",
    "        else:\n",
    "            product_desc.append('-')\n",
    "        p = soup.find('div', attrs = {'class':'_30jeq3 _16Jk6d'})\n",
    "        if p is not None:\n",
    "            price.append(p.text)\n",
    "        else:\n",
    "            price.append('-')\n",
    "        dis = soup.find('div', attrs = {'class':'_3Ay6Sb _31Dcoz pZkvcx'})\n",
    "        if dis is not None:\n",
    "            discount.append(dis.find('span').text)\n",
    "        else:\n",
    "            discount.append('-')\n",
    "    shoe_df =pd.DataFrame({'Brand':brand,\n",
    "                          'product_desc':product_desc,\n",
    "                          'price':price,\n",
    "                          'Discount':discount})\n",
    "    print(shoe_df)\n",
    "    shoe_df.to_csv('flipkart.csv', index = False)\n",
    "    \n",
    "    \n",
    "# Calling Function\n",
    "flipkart_shoe('https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
